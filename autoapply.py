#!/usr/bin/env python3
"""
AutoApply.AI - Sistema de Aplica√ß√£o Autom√°tica para Vagas
Script principal para executar busca, matching e aplica√ß√£o com gera√ß√£o de logs CSV
"""
import asyncio
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict

from loguru import logger

# Adicionar o diret√≥rio raiz ao path
sys.path.append(str(Path(__file__).parent))

from app.job_search.searcher import JobSearcher
from app.matching.matcher import JobMatcher
from app.automation.applicator_manager import ApplicatorManager
from app.automation.application_logger import ApplicationLogger, ApplicationStatus
from app.main import load_config, load_profile

async def main():
    """Fun√ß√£o principal do sistema AutoApply.AI."""
    logger.info("üöÄ AUTOAPPLY.AI - Sistema de Aplica√ß√£o Autom√°tica")
    logger.info("=" * 60)
    
    try:
        # 1. Carregar configura√ß√µes
        logger.info("üìã 1. Carregando configura√ß√µes...")
        config = load_config()
        profile = load_profile()
        
        if not config:
            logger.error("‚ùå Erro ao carregar configura√ß√µes")
            return
        
        logger.info("   ‚úÖ Configura√ß√µes carregadas")
        
        # 2. Inicializar sistema de logging
        logger.info("üìä 2. Inicializando sistema de logging...")
        app_logger = ApplicationLogger()
        app_logger.start_session()
        logger.info(f"   ‚úÖ Sess√£o iniciada: {app_logger.session_id}")
        
        # 3. Buscar vagas
        logger.info("üîç 3. Iniciando busca de vagas...")
        searcher = JobSearcher(config, app_logger)
        all_jobs = await searcher.search()
        
        logger.info(f"   üìä Total de vagas encontradas: {len(all_jobs)}")
        
        if not all_jobs:
            logger.warning("   ‚ö†Ô∏è Nenhuma vaga encontrada. Usando dados de teste...")
            from app.job_search.models import JobPosting
            all_jobs = [
                JobPosting(
                    title="Senior Python Developer",
                    description="Desenvolvedor Python s√™nior para projeto remoto",
                    email="jobs@company.com",
                    url="https://example.com/job1"
                ),
                JobPosting(
                    title="React Frontend Developer",
                    description="Desenvolvedor React para aplica√ß√£o web",
                    email="hr@startup.com",
                    url="https://example.com/job2"
                )
            ]
        
        # 4. Fazer matching das vagas
        logger.info("üéØ 4. Fazendo matching das vagas...")
        matcher = JobMatcher(config)
        matches = matcher.match_jobs(all_jobs)
        
        logger.info(f"   üìä Vagas com match: {len(matches)}")
        
        if not matches:
            logger.warning("   ‚ö†Ô∏è Nenhuma vaga com match encontrada!")
            return
        
        # 5. Aplicar para vagas (MAXIMIZAR APLICA√á√ïES - SEM DUPLICATAS)
        logger.info("\nüìù 5. Aplicando para vagas (M√ÅXIMO DE APLICA√á√ïES - SEM DUPLICATAS)...")
        applicator = ApplicatorManager(config)
        applicator.start_session()  # Start application session
        
        # Configura√ß√µes para maximizar aplica√ß√µes
        max_applications = config.get('search', {}).get('max_applications_per_day', 50)
        max_concurrent = config.get('search', {}).get('max_concurrent_applications', 10)
        application_delay = config.get('search', {}).get('application_delay', 5)
        
        logger.info(f"   üéØ Meta de aplica√ß√µes: {max_applications}")
        logger.info(f"   ‚ö° Aplica√ß√µes concorrentes: {max_concurrent}")
        logger.info(f"   ‚è±Ô∏è Delay entre aplica√ß√µes: {application_delay}s")
        logger.info(f"   üö´ Sistema anti-duplica√ß√£o: ATIVO")
        
        # Filtrar vagas √∫nicas (sem duplicatas)
        unique_matches = []
        seen_jobs = set()
        
        for match in matches:
            if isinstance(match, dict):
                job_title = match.get('title', '')
                company = match.get('company', 'Unknown')
                url = match.get('url', '')
            else:
                job_title = getattr(match.job, 'title', '')
                company = getattr(match.job, 'company', 'Unknown')
                url = getattr(match.job, 'url', '')
            
            # Create unique identifier
            job_id = f"{job_title}_{company}_{url}"
            
            if job_id not in seen_jobs:
                seen_jobs.add(job_id)
                unique_matches.append(match)
        
        logger.info(f"   üîç Vagas √∫nicas encontradas: {len(unique_matches)} (filtradas de {len(matches)})")
        
        if not unique_matches:
            logger.warning("   ‚ö†Ô∏è Nenhuma vaga √∫nica encontrada ap√≥s filtro de duplicatas!")
            return
        
        # Aplicar para vagas √∫nicas
        applications_to_process = min(max_applications, len(unique_matches))
        logger.info(f"   üìã Aplicando para {applications_to_process} vagas √∫nicas...")
        
        successful_applications = 0
        failed_applications = 0
        duplicate_applications = 0
        already_applied = 0
        
        # Processar em lotes para evitar sobrecarga
        batch_size = max_concurrent
        total_batches = (applications_to_process + batch_size - 1) // batch_size
        
        for i in range(0, applications_to_process, batch_size):
            batch = unique_matches[i:i + batch_size]
            batch_num = (i // batch_size) + 1
            
            logger.info(f"   üîÑ Processando lote {batch_num}/{total_batches}")
            
            # Processar lote em paralelo
            batch_tasks = []
            for j, match in enumerate(batch, 1):
                task = asyncio.create_task(_apply_to_job(match, i + j, app_logger))
                batch_tasks.append(task)
            
            # Aguardar conclus√£o do lote
            batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)
            
            # Contar resultados
            for result in batch_results:
                if isinstance(result, dict):
                    if result.get('status') == 'applied':
                        successful_applications += 1
                    elif result.get('status') == 'duplicate':
                        duplicate_applications += 1
                    elif result.get('status') == 'already_applied':
                        already_applied += 1
                    else:
                        failed_applications += 1
            
            # Aguardar antes do pr√≥ximo lote
            if i + batch_size < applications_to_process:
                logger.info(f"   ‚è±Ô∏è Aguardando {application_delay}s antes do pr√≥ximo lote...")
                await asyncio.sleep(application_delay)
        
        # Resumo final
        logger.info(f"   ‚úÖ Aplica√ß√µes bem-sucedidas: {successful_applications}")
        logger.info(f"   ‚ùå Aplica√ß√µes falharam: {failed_applications}")
        logger.info(f"   üîÑ Vagas duplicadas detectadas: {duplicate_applications}")
        logger.info(f"   üìö J√° aplicado anteriormente: {already_applied}")
        logger.info(f"   üìà Taxa de sucesso efetiva: {(successful_applications/(successful_applications+failed_applications)*100):.1f}%")
        
        # 6. Finalizar sess√£o e gerar relat√≥rio
        logger.info("\nüìä 6. Finalizando sess√£o e gerando relat√≥rio...")
        session_log = app_logger.end_session()
        
        # Mostrar caminhos dos arquivos CSV
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        csv_report_path = f"data/logs/autoapply_report_{timestamp}.csv"
        summary_csv_path = f"data/logs/autoapply_summary_{timestamp}.csv"
        
        logger.info("\n" + "=" * 60)
        logger.info("üìà RELAT√ìRIO FINAL")
        logger.info("=" * 60)
        logger.info(f"üìä Total de vagas encontradas: {len(all_jobs)}")
        logger.info(f"üéØ Vagas com match: {len(matches)}")
        logger.info(f"üìù Aplica√ß√µes realizadas: {successful_applications}")
        logger.info(f"‚úÖ Aplica√ß√µes bem-sucedidas: {successful_applications}")
        logger.info(f"‚ùå Aplica√ß√µes falharam: {failed_applications}")
        logger.info(f"üìà Taxa de sucesso: {(successful_applications/(successful_applications+failed_applications)*100):.1f}%")
        logger.info(f"üìÅ Logs salvos em: data/logs/")
        logger.info(f"üìÑ Relat√≥rio: data/logs/reports/session_{timestamp}_report.txt")
        logger.info(f"üìä CSV detalhado: {csv_report_path}")
        logger.info(f"üìã CSV resumo: {summary_csv_path}")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"‚ùå Erro durante execu√ß√£o: {str(e)}")
        raise

async def _apply_to_job(match, job_number: int, app_logger) -> Dict:
    """Apply to a specific job."""
    try:
        # Preparar dados da vaga
        if isinstance(match, dict):
            job_data = match
            score = match.get('match_score', 0)
        else:
            job_data = {
                'title': match.job.title,
                'company': getattr(match.job, 'company', 'Unknown'),
                'url': match.job.url,
                'description': match.job.description
            }
            score = getattr(match, 'match_score', 0)
        
        # Log da aplica√ß√£o
        logger.info(f"   üìÑ Aplica√ß√£o {job_number}: {job_data.get('title', 'Unknown')}")
        logger.info(f"      Score: {score:.1f}%")
        logger.info(f"      URL: {job_data.get('url', 'N/A')}")
        
        # Verificar se √© duplicata antes de aplicar
        is_duplicate, duplicate_type, existing_hash = app_logger._is_duplicate_job(job_data)
        
        if is_duplicate:
            if duplicate_type == "already_applied":
                logger.info(f"      ‚ö†Ô∏è J√° aplicado anteriormente - PULANDO")
                app_logger.log_job_application(
                    job_data, 
                    ApplicationStatus.ALREADY_APPLIED, 
                    score, 
                    platform="AutoApply.AI"
                )
                return {'status': 'already_applied', 'success': False}
            else:
                logger.info(f"      ‚ö†Ô∏è Vaga duplicada detectada - PULANDO")
                app_logger.log_job_application(
                    job_data, 
                    ApplicationStatus.DUPLICATE, 
                    score, 
                    platform="AutoApply.AI"
                )
                return {'status': 'duplicate', 'success': False}
        
        # Simular aplica√ß√£o
        logger.info(f"      üîÑ Simulando aplica√ß√£o...")
        await asyncio.sleep(1)  # Simular tempo de aplica√ß√£o
        
        # Log da aplica√ß√£o bem-sucedida
        app_logger.log_job_application(
            job_data, 
            ApplicationStatus.APPLIED, 
            score, 
            platform="AutoApply.AI"
        )
        
        logger.info(f"      ‚úÖ Aplica√ß√£o simulada com sucesso")
        return {'status': 'applied', 'success': True}
        
    except Exception as e:
        logger.error(f"      ‚ùå Erro na aplica√ß√£o: {str(e)}")
        app_logger.log_job_application(
            job_data, 
            ApplicationStatus.FAILED, 
            score, 
            error=str(e),
            platform="AutoApply.AI"
        )
        return {'status': 'failed', 'success': False, 'error': str(e)}

if __name__ == "__main__":
    asyncio.run(main())
